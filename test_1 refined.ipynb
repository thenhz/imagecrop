{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rOvvWAVTkMR7"
   },
   "source": [
    "# Intro to Object Detection Colab\n",
    "\n",
    "Welcome to the object detection colab!  This demo will take you through the steps of running an \"out-of-the-box\" detection model on a collection of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPs64QA1Zdov"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "LBZ9VWZZFUCT",
    "outputId": "6b94014a-6425-4750-afaf-509dbe687f3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.2.0\n",
      "  Downloading tensorflow-2.2.0-cp38-cp38-manylinux2010_x86_64.whl (516.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 516.3 MB 8.6 kB/s eta 0:00:01    |██▎                             | 37.1 MB 2.0 MB/s eta 0:04:03     |███████▍                        | 118.3 MB 1.8 MB/s eta 0:03:42     |█████████▉                      | 159.2 MB 2.4 MB/s eta 0:02:31     |███████████████████▎            | 311.7 MB 2.8 MB/s eta 0:01:14     |███████████████████████████▏    | 438.7 MB 3.0 MB/s eta 0:00:27\n",
      "\u001b[?25hCollecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from tensorflow==2.2.0) (1.11.2)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.15.0rc1-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.12.0 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from tensorflow==2.2.0) (1.15.0)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse==1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hProcessing /home/thenhz/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501/termcolor-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from tensorflow==2.2.0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from tensorflow==2.2.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /home/thenhz/anaconda3/lib/python3.8/site-packages (from tensorflow==2.2.0) (0.34.2)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.35.0-cp38-cp38-manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.0 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (49.2.0.post20200714)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.24.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.26.1-py2.py3-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/thenhz/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Installing collected packages: protobuf, tensorboard-plugin-wit, absl-py, grpcio, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard, opt-einsum, google-pasta, astunparse, tensorflow-estimator, termcolor, gast, keras-preprocessing, scipy, tensorflow\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.0\n",
      "    Uninstalling scipy-1.5.0:\n",
      "      Successfully uninstalled scipy-1.5.0\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.1 gast-0.3.3 google-auth-1.26.1 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.35.0 keras-preprocessing-1.1.2 markdown-3.3.3 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.15.0rc1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7 scipy-1.4.1 tensorboard-2.2.2 tensorboard-plugin-wit-1.8.0 tensorflow-2.2.0 tensorflow-estimator-2.2.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U --pre tensorflow==\"2.2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "oi28cqGGFWnY",
    "outputId": "bfd0d9e0-d13e-43ba-9081-287a43ace633"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NwdsBdGhFanc",
    "outputId": "8eda3f53-2caf-43f9-c3c3-caafea8243c5"
   },
   "outputs": [],
   "source": [
    "# Install the Object Detection API\n",
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yn5_uV1HLvaz"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa75b256370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "foo = np.zeros((640,480))\n",
    "plt.imshow(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IogyryF2lFBL"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-y9R0Xllefec"
   },
   "outputs": [],
   "source": [
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4YjnOjME1gy"
   },
   "outputs": [],
   "source": [
    "from bricks.CenterNet import CenterNet\n",
    "import os\n",
    "# @title Choose the model to use, then evaluate the cell.\n",
    "MODELS = {\n",
    "    'centernet_with_keypoints': 'center_net_hg104_512x512_kpts_coco17_tpu-32', \n",
    "    'centernet_without_keypoints': 'center_net_hg104_512x512_coco17_tpu-8'\n",
    "}\n",
    "\n",
    "model_display_name = 'centernet_with_keypoints' # @param ['centernet_with_keypoints', 'centernet_without_keypoints']\n",
    "model_name = MODELS[model_display_name]\n",
    "\n",
    "# Download the checkpoint and put it into models/research/object_detection/test_data/\n",
    "\n",
    "if model_display_name == 'centernet_with_keypoints':\n",
    "    if(not os.path.exists(\"centernet_hg104_512x512_kpts_coco17_tpu-32\")):\n",
    "        !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_512x512_kpts_coco17_tpu-32.tar.gz\n",
    "        !tar -xf centernet_hg104_512x512_kpts_coco17_tpu-32.tar.gz\n",
    "        !mv centernet_hg104_512x512_kpts_coco17_tpu-32/checkpoint models/research/object_detection/test_data/\n",
    "    model_instance = CenterNet(\n",
    "        pipeline_config = 'models/research/object_detection/configs/tf2/center_net_hourglass104_512x512_coco17_tpu-8.config', \n",
    "        model_dir = 'models/research/object_detection/test_data/checkpoint/'\n",
    "    )\n",
    "if model_display_name == 'centernet_without_keypoints':\n",
    "    if(not os.path.exists(\"centernet_hg104_512x512_kpts_coco17_tpu-32\")):\n",
    "        !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_512x512_coco17_tpu-8.tar.gz\n",
    "        !tar -xf centernet_hg104_512x512_coco17_tpu-8.tar.gz\n",
    "        !mv centernet_hg104_512x512_coco17_tpu-8/checkpoint models/research/object_detection/test_data/\n",
    "    model_instance = CenterNet(\n",
    "        pipeline_config = '../models/research/object_detection/configs/tf2/center_net_hourglass104_512x512_coco17_tpu-8.config', \n",
    "        model_dir = '../models/research/object_detection/test_data/checkpoint/'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path = '../data/imagecrop/fantastic-four-movie-wallpaper-ultra-hd-4k-70140.jpg'\n",
    "#image_path = '../data/imagecrop/wallpapertip_4k-movie-wallpaper_2513441.jpg'\n",
    "image_path = '/mnt/c/Users/alessandro.colombo/Pictures/fanart.tv/backgrounds/a-fantastic-fear-of-everything___a-fantastic-fear-of-everything-5c6668a4e419e.jpg'\n",
    "image_np = load_image_into_numpy_array(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thenhz/anaconda3/lib/python3.8/site-packages/object_detection/meta_architectures/center_net_meta_arch.py:302: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thenhz/anaconda3/lib/python3.8/site-packages/object_detection/meta_architectures/center_net_meta_arch.py:302: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "detections = model_instance.get_detections(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-eee4375e6f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection_scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "### \n",
    "classes_weight = {\n",
    "    \"kite\": 100,\n",
    "    \"person\": 1,\n",
    "    \"surfboard\":1\n",
    "}\n",
    "\n",
    "#test_image = 'models/research/object_detection/test_images/image2.jpg'\n",
    "orig_im = Image.open(image_path)\n",
    "im_width, im_height = orig_im.size\n",
    "pil_im = Image.new('L', (im_width, im_height))\n",
    "\n",
    "np_im = np.asarray(pil_im).copy()\n",
    "print(np_im.shape)\n",
    "\n",
    "scores = detections['detection_scores'][0].numpy()\n",
    "for idx, bbox in enumerate(detections['detection_boxes'][0].numpy()):  \n",
    "    if scores[idx] > 0.30:\n",
    "        ymin, xmin, ymax, xmax = tuple(bbox.tolist())\n",
    "        (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                      ymin * im_height, ymax * im_height)\n",
    "        if detections['detection_classes_name'][idx] in classes_weight:\n",
    "            obj_score = classes_weight[detections['detection_classes_name'][idx]]#classes_weight[category_index[classes_detected[idx]]['name']]\n",
    "            np_im[int(top):int(bottom),int(left):int(right)] = obj_score\n",
    "\n",
    "            #detected_classes_text[STANDARD_COLORS[classes_detected[idx]]] = category_index[classes_detected[idx]]['name']\n",
    "\n",
    "plt.figure(figsize=(15,20))\n",
    "plt.imshow(np_im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: gestire i crop che sono troppo piccoli quando le dimensioni non quagliano con l'immagine originale (agire sul sizes a runtime??)\n",
    "#TODO: usare tecniche come la regola dei terzi & co\n",
    "#TODO: fare in modo di poter fare plug di ulteriori detector\n",
    "def make_crop_coordinates_nhz(image, ratio_str):\n",
    "    if ratio_str == \"16_9\":\n",
    "        ratio = 0.5625\n",
    "    if ratio_str == \"4_3\":\n",
    "        ratio = 0.75\n",
    "    if ratio_str == \"1_1\":\n",
    "        ratio = 1\n",
    "    if ratio_str == \"9_16\":\n",
    "        ratio = 1.7777\n",
    "    if ratio_str == \"3_4\":\n",
    "        ratio = 1.3333\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    coodinates = []\n",
    "    shorter_dimension = min(width, height)\n",
    "    position_step = shorter_dimension / 80\n",
    "    sizes = [width * 0.6,width * 0.7,width * 0.8, width * 0.9, width]\n",
    "    for size in sizes:\n",
    "        position_width = 0\n",
    "        crop_height = int(size * ratio)\n",
    "        crop_width = int(size)\n",
    "        while True:\n",
    "            position_height = 0\n",
    "            while True:\n",
    "                if position_height + crop_height > height:\n",
    "                    break\n",
    "                    \n",
    "                new_coord = (position_width, position_height,\n",
    "                                   position_width + int(size), position_height + crop_height)\n",
    "                coodinates.append(new_coord)\n",
    "                #print(new_coord)\n",
    "                #print(\"INCREASING HEIGHT\")\n",
    "                position_height += position_step\n",
    "                \n",
    "            position_width += position_step\n",
    "            #print(\"INCREASING WIDTH\")\n",
    "            if position_width + crop_width > width:\n",
    "                #print(\"**********************\")\n",
    "                break\n",
    "            \n",
    "    return coodinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(orig_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crops = make_crop_coordinates_nhz(np_im,\"4_3\")\n",
    "\n",
    "best_score = -1\n",
    "best_crop = []\n",
    "\n",
    "for crop in crops:\n",
    "    #TODO: add rule of thirds, avoid partial classes crop,etc.. to the score\n",
    "    candidate_score = np.sum(np_im[int(crop[1]):int(crop[3]),int(crop[0]):int(crop[2])])\n",
    "    #print(crop)\n",
    "    #print(candidate_score)\n",
    "    if best_score < candidate_score:\n",
    "        best_crop = crop\n",
    "        best_score = candidate_score\n",
    "        \n",
    "print(\"BEST:\",best_crop)\n",
    "if best_crop:\n",
    "    plt.figure(figsize=(16,9))\n",
    "    #plt.imshow(np_im[int(best_crop[1]):int(best_crop[3]),int(best_crop[0]):int(best_crop[2])])\n",
    "    plt.imshow(orig_im.crop(best_crop))\n",
    "else:\n",
    "    print(\"No candidates\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "inference_tf2_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
